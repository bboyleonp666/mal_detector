{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d799520-af6a-4966-9ca6-0b7d5b95c1bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions\n",
      "--------------------\n",
      "Pytorch              1.13.1+cu117\n",
      "Pytorch-Geometric    2.2.0\n",
      "--------------------\n",
      "GPU Support          True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch_geometric as pyg\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from models import GCN\n",
    "from utils import read_pickle, split_df, get_file_paths, DataProcessor\n",
    "\n",
    "print('Versions')\n",
    "print('-' * 20)\n",
    "print(f'{\"Pytorch\":<20} {torch.__version__}')\n",
    "print(f'{\"Pytorch-Geometric\":<20} {pyg.__version__}')\n",
    "print('-' * 20)\n",
    "print(f'{\"GPU Support\":<20} {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b043aa-d426-41bc-b7ff-7c1e90f34884",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha256</th>\n",
       "      <th>path</th>\n",
       "      <th>family</th>\n",
       "      <th>threshold</th>\n",
       "      <th>arch</th>\n",
       "      <th>label</th>\n",
       "      <th>malicious</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1263d19ea264fd53e7d21755752b37101ba247ed6d0e24...</td>\n",
       "      <td>FCGs/mal_graphs/1263d19ea264fd53e7d21755752b37...</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>True</td>\n",
       "      <td>x86el</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48309f7ef98e9597eedacc02fba7ba3761e6f00712adbb...</td>\n",
       "      <td>FCGs/mal_graphs/48309f7ef98e9597eedacc02fba7ba...</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>True</td>\n",
       "      <td>x86el</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f399487df0dd96d02f6a4a95b1dd4f6e1934d92463d06f...</td>\n",
       "      <td>FCGs/mal_graphs/f399487df0dd96d02f6a4a95b1dd4f...</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>True</td>\n",
       "      <td>x86el</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a9451891dd42875fb275a14cf7b5970d3de488f6557d12...</td>\n",
       "      <td>FCGs/mal_graphs/a9451891dd42875fb275a14cf7b597...</td>\n",
       "      <td>Bashlite</td>\n",
       "      <td>True</td>\n",
       "      <td>x86el</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80dca6a3359ca5becb1d1bf0cf405249b6200caa2c97bd...</td>\n",
       "      <td>FCGs/mal_graphs/80dca6a3359ca5becb1d1bf0cf4052...</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>True</td>\n",
       "      <td>x86el</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sha256  \\\n",
       "0  1263d19ea264fd53e7d21755752b37101ba247ed6d0e24...   \n",
       "1  48309f7ef98e9597eedacc02fba7ba3761e6f00712adbb...   \n",
       "2  f399487df0dd96d02f6a4a95b1dd4f6e1934d92463d06f...   \n",
       "3  a9451891dd42875fb275a14cf7b5970d3de488f6557d12...   \n",
       "4  80dca6a3359ca5becb1d1bf0cf405249b6200caa2c97bd...   \n",
       "\n",
       "                                                path    family threshold  \\\n",
       "0  FCGs/mal_graphs/1263d19ea264fd53e7d21755752b37...     Mirai      True   \n",
       "1  FCGs/mal_graphs/48309f7ef98e9597eedacc02fba7ba...     Mirai      True   \n",
       "2  FCGs/mal_graphs/f399487df0dd96d02f6a4a95b1dd4f...     Mirai      True   \n",
       "3  FCGs/mal_graphs/a9451891dd42875fb275a14cf7b597...  Bashlite      True   \n",
       "4  FCGs/mal_graphs/80dca6a3359ca5becb1d1bf0cf4052...     Mirai      True   \n",
       "\n",
       "    arch  label  malicious  \n",
       "0  x86el      0          1  \n",
       "1  x86el      0          1  \n",
       "2  x86el      0          1  \n",
       "3  x86el      1          1  \n",
       "4  x86el      0          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = True\n",
    "\n",
    "data_info = 'dataset.csv'\n",
    "fcg_dir = 'FCGs/'\n",
    "w2v_path = 'model_saved/word2vec.wordvectors'\n",
    "gnn_path = 'model_saved/gcn.pt'\n",
    "\n",
    "fpaths = get_file_paths(fcg_dir)\n",
    "fnames = [os.path.splitext(os.path.basename(path))[0] for path in fpaths]\n",
    "exist_df = pd.DataFrame({'sha256': fnames, 'path': fpaths})\n",
    "\n",
    "islab_names = {'sha256': str, 'family': str, 'threshold': str, 'arch': str}\n",
    "islab_df = pd.read_csv(data_info, low_memory=False, names=islab_names, dtype=islab_names, skiprows=1)\n",
    "islab_df = islab_df[~islab_df.family.isin(['Unknown'])]\n",
    "ds_df = islab_df[islab_df.arch.isin(['x86el', 'x86_64el'])]\n",
    "ds_df = exist_df.merge(ds_df, how='inner')\n",
    "\n",
    "mal_dict = {fam: int(fam!='BenignWare') for fam in ds_df.family.unique()}\n",
    "family_dict = {fam: i for i, fam in enumerate(ds_df.family.unique())}\n",
    "\n",
    "ds_df = ds_df.assign(label=ds_df.family.map(family_dict))\n",
    "ds_df = ds_df.assign(malicious=ds_df.family.map(mal_dict))\n",
    "ds_df = ds_df.reset_index(drop=True)\n",
    "ds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1eb2d0d-01ed-4619-ba28-10a679948e00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenignWare    14659\n",
       "Bashlite      12541\n",
       "Mirai         11552\n",
       "Android        1993\n",
       "Tsunami        1402\n",
       "Xorddos         603\n",
       "Dofloo          594\n",
       "Pnscan           13\n",
       "Name: family, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df.family.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b97d721e-01ba-4703-9ce6-ca532d0d5452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processor = DataProcessor()\n",
    "processor.load(w2v_path)\n",
    "\n",
    "def get_data(path, label):\n",
    "    G = read_pickle(path)\n",
    "    if len(G.edges) == 0:\n",
    "        # will be filtered out later\n",
    "        return None\n",
    "    \n",
    "    x, edge_index = processor.from_networkx(G)\n",
    "    return Data(x=x, edge_index=edge_index, y=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e021078-b7fe-46c4-8b69-0986ca41e45a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Training ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 70.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Validation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:12<00:00, 31.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train in total: 20\n",
      "Valid in total: 388\n"
     ]
    }
   ],
   "source": [
    "num_train = 10\n",
    "num_valid = 200\n",
    "workers = 20\n",
    "column = 'malicious' if detector else 'label'\n",
    "\n",
    "train_df, valid_df = split_df(df=ds_df,    n_or_frac=num_train, column=column, shuffle=True, allow_lower_n=True)\n",
    "valid_df, test_df  = split_df(df=valid_df, n_or_frac=num_valid, column=column, shuffle=True, allow_lower_n=True)\n",
    "train_pairs = train_df[['path', column]].to_numpy()\n",
    "valid_pairs = valid_df[['path', column]].to_numpy()\n",
    "\n",
    "print('Processing Training ...')\n",
    "train_ds = Parallel(n_jobs=workers)(delayed(get_data)(path, label) for path, label in tqdm(train_pairs))\n",
    "train_ds = [data for data in train_ds if not data is None]\n",
    "print('Processing Validation ...')\n",
    "valid_ds = Parallel(n_jobs=workers)(delayed(get_data)(path, label) for path, label in tqdm(valid_pairs))\n",
    "valid_ds = [data for data in valid_ds if not data is None]\n",
    "\n",
    "print(f'Train in total: {len(train_ds)}')\n",
    "print(f'Valid in total: {len(valid_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd487ba9-842b-4800-85e8-6d26c28bc612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "class TorchTrainer:\n",
    "    def __init__(self, model, optimizer=None, criterion=None, device=None):\n",
    "        self.model     = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
    "                \n",
    "        self.arguments = locals()\n",
    "        self.arguments['device'] = self.device\n",
    "    \n",
    "    def train(self, train_loader, valid_loader, epochs=20, save_path='model_saved/gcn_model.pt', verbose=True):\n",
    "        self.arguments['epochs'] = epochs\n",
    "        self.arguments['save_path'] = save_path\n",
    "        \n",
    "        train_acc  = np.zeros(epochs)\n",
    "        train_loss = np.zeros(epochs)\n",
    "        val_acc    = np.zeros(epochs)\n",
    "        val_loss   = np.zeros(epochs)\n",
    "        train_time = np.zeros(epochs)\n",
    "        \n",
    "        best_val_acc = 0\n",
    "        for epoch in range(epochs):\n",
    "            if verbose:\n",
    "                epoch_start = f'Epoch ({epoch + 1}/{epochs})'\n",
    "                print(epoch_start, end=' ')\n",
    "\n",
    "            train_time[epoch] = self.train_epoch(train_loader)\n",
    "\n",
    "            # evaluate the training accuracy and validation accuracy after each epoch\n",
    "            train_acc[epoch], train_loss[epoch] = self.test(train_loader)\n",
    "            val_acc[epoch], val_loss[epoch] = self.test(valid_loader)\n",
    "\n",
    "            if val_acc[epoch] > best_val_acc:\n",
    "                # save the best model according to validation accuracy\n",
    "                best_val_acc = val_acc[epoch]\n",
    "                torch.save(self.model, save_path)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'Train Acc: {train_acc[epoch]:.4f}, Train Loss: {train_loss[epoch]:>7.6f}', end=', ')\n",
    "                print(f'Val Acc: {val_acc[epoch]:.4f}, Val Loss: {val_loss[epoch]:>7.6f}', end=' -- ')\n",
    "                print(f'Training Time: {train_time[epoch]:.2f}s')\n",
    "        \n",
    "        self.history = {'train_acc':  train_acc, \n",
    "                        'train_loss': train_loss, \n",
    "                        'val_acc':    val_acc, \n",
    "                        'val_loss':   val_loss, \n",
    "                        'time':       train_time}\n",
    "\n",
    "    def train_epoch(self, train_loader):\n",
    "        start = time()\n",
    "        \n",
    "        self.model.train()\n",
    "        for data in train_loader:               # Iterate in batches over the training dataset.\n",
    "            data.to(self.device)                # Train the data if gpu is available\n",
    "            out = self.model(data)              # Perform a single forward pass.\n",
    "            loss = self.criterion(out, data.y)  # Compute the loss.\n",
    "            \n",
    "            loss.backward()                     # Derive gradients.\n",
    "            self.optimizer.step()               # Update parameters based on gradients.\n",
    "            self.optimizer.zero_grad()          # Clear gradients.\n",
    "        \n",
    "        end = time()\n",
    "        return end - start\n",
    "\n",
    "    def test(self, loader):\n",
    "        self.model.eval()\n",
    "\n",
    "        loss = 0\n",
    "        correct = 0\n",
    "        for data in loader:                             # Iterate in batches over the training/test dataset.\n",
    "            data.to(self.device)                        # Train the data if gpu is available\n",
    "            out = self.model(data)                      # Predict the outcome by trained model\n",
    "            pred = out.argmax(dim=1)                    # Use the class with highest probability.\n",
    "\n",
    "            correct += int((pred == data.y).sum())      # Check against ground-truth labels.\n",
    "            loss += self.criterion(out, data.y).item()  # Get the loss accumulated of each data sample\n",
    "\n",
    "        acc = correct / len(loader.dataset)             # Get the accuracy\n",
    "        avg_loss = loss / len(loader.dataset)           # Get the average loss\n",
    "        return (acc, avg_loss)                          # Return the accuracy and average loss\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model = torch.load(path)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict(self, loader):\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                data.to(self.device)\n",
    "                pred = self.model.predict_prob(data).cpu().detach()\n",
    "                preds.append(pred)\n",
    "        preds = torch.vstack(preds)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3773dbf6-4bfc-4f78-8fcb-c1f4410cbda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs     = 20\n",
    "batch_size = 64\n",
    "device     = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_features = train_ds[0].num_node_features\n",
    "num_classes  = len(ds_df[column].unique())\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, num_workers=0, drop_last=True, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=128, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8db43476-7b76-4d51-8dab-2d7cd56a6b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Model: \n",
      "GCN(\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Optimizer: \n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: False\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Criterion: CrossEntropyLoss()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = GCN(num_features=num_features, hidden_channels=64, num_classes=num_classes).to(device)\n",
    "\n",
    "# define device of model before sending to the optimizer model.parameters() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "print(f'Device: {device}\\n')\n",
    "print(f'Model: \\n{model}\\n')\n",
    "print(f'Optimizer: \\n{optimizer}\\n')\n",
    "print(f'Criterion: {criterion}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd09c802-50b9-43ef-9ecd-50dd7e3e22a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (1/20) Train Acc: 0.9868, Train Loss: 0.001252, Val Acc: 0.9709, Val Loss: 0.000903 -- Training Time: 2.34s\n",
      "Epoch (2/20) Train Acc: 0.9849, Train Loss: 0.000917, Val Acc: 0.9699, Val Loss: 0.000723 -- Training Time: 1.70s\n",
      "Epoch (3/20) Train Acc: 0.9837, Train Loss: 0.001079, Val Acc: 0.9694, Val Loss: 0.000656 -- Training Time: 1.76s\n",
      "Epoch (4/20) Train Acc: 0.9815, Train Loss: 0.001155, Val Acc: 0.9694, Val Loss: 0.000624 -- Training Time: 2.02s\n",
      "Epoch (5/20) Train Acc: 0.9760, Train Loss: 0.173333, Val Acc: 0.9591, Val Loss: 0.114253 -- Training Time: 2.01s\n",
      "Epoch (6/20) Train Acc: 0.9608, Train Loss: 0.042015, Val Acc: 0.9401, Val Loss: 0.030211 -- Training Time: 2.03s\n",
      "Epoch (7/20) Train Acc: 0.9835, Train Loss: 0.056541, Val Acc: 0.9663, Val Loss: 0.022814 -- Training Time: 1.83s\n",
      "Epoch (8/20) Train Acc: 0.9898, Train Loss: 0.015491, Val Acc: 0.9743, Val Loss: 0.010488 -- Training Time: 1.93s\n",
      "Epoch (9/20) Train Acc: 0.9727, Train Loss: 0.296055, Val Acc: 0.9607, Val Loss: 0.123098 -- Training Time: 2.04s\n",
      "Epoch (10/20) Train Acc: 0.9899, Train Loss: 0.024033, Val Acc: 0.9761, Val Loss: 0.011263 -- Training Time: 1.81s\n",
      "Epoch (11/20) Train Acc: 0.9918, Train Loss: 0.019588, Val Acc: 0.9789, Val Loss: 0.004635 -- Training Time: 1.90s\n",
      "Epoch (12/20) Train Acc: 0.9918, Train Loss: 0.008249, Val Acc: 0.9784, Val Loss: 0.001666 -- Training Time: 1.95s\n",
      "Epoch (13/20) Train Acc: 0.9942, Train Loss: 0.007139, Val Acc: 0.9797, Val Loss: 0.001370 -- Training Time: 1.28s\n",
      "Epoch (14/20) Train Acc: 0.9882, Train Loss: 0.071236, Val Acc: 0.9727, Val Loss: 0.157478 -- Training Time: 1.93s\n",
      "Epoch (15/20) Train Acc: 0.9930, Train Loss: 0.004057, Val Acc: 0.9794, Val Loss: 0.000896 -- Training Time: 1.89s\n",
      "Epoch (16/20) Train Acc: 0.9927, Train Loss: 0.008830, Val Acc: 0.9797, Val Loss: 0.002092 -- Training Time: 1.59s\n",
      "Epoch (17/20) Train Acc: 0.9939, Train Loss: 0.011364, Val Acc: 0.9802, Val Loss: 0.003545 -- Training Time: 1.51s\n",
      "Epoch (18/20) Train Acc: 0.9940, Train Loss: 0.003087, Val Acc: 0.9787, Val Loss: 0.001174 -- Training Time: 1.28s\n",
      "Epoch (19/20) Train Acc: 0.9927, Train Loss: 0.002475, Val Acc: 0.9805, Val Loss: 0.001495 -- Training Time: 1.28s\n",
      "Epoch (20/20) Train Acc: 0.9959, Train Loss: 0.001521, Val Acc: 0.9820, Val Loss: 0.003712 -- Training Time: 1.32s\n"
     ]
    }
   ],
   "source": [
    "trainer = TorchTrainer(model, optimizer=optimizer, criterion=criterion, device=device)\n",
    "trainer.train(train_loader=train_loader, \n",
    "              valid_loader=valid_loader, \n",
    "              epochs=20, \n",
    "              save_path='model_saved/gcn_model.pt', \n",
    "              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b281f8-96bd-4c35-aef0-7a87628d2721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9045e93-8691-4d50-b7db-ef00bc13a4fe",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beac23f6-c329-438a-bada-4f896b1f52a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = GCN(num_features=num_features, hidden_channels=64, num_classes=num_classes).to(device)\n",
    "new_trainer = TorchTrainer(new_model)\n",
    "new_trainer.load('model_saved/gcn_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "190bc931-b73a-4bee-83de-473a9e64f0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = new_trainer.predict(valid_loader)\n",
    "predictions.argmax(dim=1)\n",
    "# predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aecf3c17-0602-4f07-8f12-e7d00a57a1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label = [data.y for data in valid_loader.dataset]\n",
    "torch.tensor(real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a4011-dffc-407e-9b04-743898c56ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "deb9bcae-5840-4744-8757-02554afcf040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def function_timer(some_function):\n",
    "    from time import time\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time()\n",
    "        result = some_function(*args, **kwargs)\n",
    "        end = time()-t1\n",
    "        return result, end\n",
    "    return wrapper\n",
    "\n",
    "@function_timer\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:                             # Iterate in batches over the training dataset.\n",
    "        data.to(device)                                   # Train the data if gpu is available\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)                     # Compute the loss.\n",
    "        # print(help(loss))\n",
    "        loss.backward()                                   # Derive gradients.\n",
    "        optimizer.step()                                  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()                             # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    for data in loader:                                   # Iterate in batches over the training/test dataset.\n",
    "        data.to(device)                                   # Train the data if gpu is available\n",
    "        out = model(data.x, data.edge_index, data.batch)  # Predict the outcome by trained model\n",
    "        pred = out.argmax(dim=1)                          # Use the class with highest probability.\n",
    "        \n",
    "        correct += int((pred == data.y).sum())            # Check against ground-truth labels.\n",
    "        loss += criterion(out, data.y).item()             # Get the loss accumulated of each data sample\n",
    "        \n",
    "    acc = correct / len(loader.dataset)                   # Get the accuracy\n",
    "    avg_loss = loss / len(loader.dataset)                 # Get the average loss\n",
    "    \n",
    "    return (acc, avg_loss)                                # Return the accuracy and average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c1c40f5-6e30-4b74-8e17-1c6470af14bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, num_workers=0, drop_last=True, shuffle=True, pin_memory=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=128, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0a4817a-e725-414c-9f59-671100346ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "\n",
      "Model:\n",
      "GCN(\n",
      "  (conv1): GCNConv(128, 64)\n",
      "  (conv2): GCNConv(64, 64)\n",
      "  (lin): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_sample = train_loader.dataset[0]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(num_features=data_sample.num_node_features, hidden_channels=64, num_classes=len(ds_df[column].unique())).to(device)\n",
    "print(f'Device: {device}')\n",
    "print()\n",
    "print(f'Model:\\n{model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba74dcba-e167-4f04-bdc6-a3f08b6ffd9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e998b347-994e-410e-8bab-4ade39d785cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch (1/20) Train Acc: 0.7865, Train Loss: 0.008178, Val Acc: 0.7808, Val Loss: 0.003963 -- Training Time: 1.67s\n",
      "Epoch (2/20) Train Acc: 0.7868, Train Loss: 0.008174, Val Acc: 0.7808, Val Loss: 0.003963 -- Training Time: 1.37s\n",
      "Epoch (3/20) Train Acc: 0.7866, Train Loss: 0.008176, Val Acc: 0.7808, Val Loss: 0.003963 -- Training Time: 1.38s\n",
      "Epoch (4/20) "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m _, _time \u001b[38;5;241m=\u001b[39m train()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# evaluate the training accuracy and validation accuracy after epoch epoch\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m train_acc[epoch], train_loss[epoch] \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m val_acc[epoch], val_loss[epoch] \u001b[38;5;241m=\u001b[39m test(valid_loader)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_acc[epoch] \u001b[38;5;241m>\u001b[39m best_val_acc:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# save the best model according to validation accuracy\u001b[39;00m\n",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     30\u001b[0m data\u001b[38;5;241m.\u001b[39mto(device)                                   \u001b[38;5;66;03m# Train the data if gpu is available\u001b[39;00m\n\u001b[1;32m     31\u001b[0m out \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch)  \u001b[38;5;66;03m# Predict the outcome by trained model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)                          \u001b[38;5;66;03m# Use the class with highest probability.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((pred \u001b[38;5;241m==\u001b[39m data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39msum())            \u001b[38;5;66;03m# Check against ground-truth labels.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)\u001b[38;5;241m.\u001b[39mitem()             \u001b[38;5;66;03m# Get the loss accumulated of each data sample\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### WARNING: If computer get overheated, the training process will become unstable\n",
    "\n",
    "## Initialize the numpy array for accuracy and loss\n",
    "train_acc = np.zeros(epochs)\n",
    "train_loss = np.zeros(epochs)\n",
    "val_acc = np.zeros(epochs)\n",
    "val_loss = np.zeros(epochs)\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_start = f'Epoch ({epoch + 1}/{epochs})'\n",
    "    print(epoch_start, end=' ')\n",
    "    \n",
    "    # since train() returns nothing, so ignore the return with '_' and fetch the time taken\n",
    "    _, _time = train()\n",
    "    \n",
    "    # evaluate the training accuracy and validation accuracy after epoch epoch\n",
    "    train_acc[epoch], train_loss[epoch] = test(train_loader)\n",
    "    val_acc[epoch], val_loss[epoch] = test(valid_loader)\n",
    "    \n",
    "    if val_acc[epoch] > best_val_acc:\n",
    "        # save the best model according to validation accuracy\n",
    "        best_val_acc = val_acc[epoch]\n",
    "        torch.save(model, gnn_path)\n",
    "    \n",
    "    print(f'Train Acc: {train_acc[epoch]:.4f}, Train Loss: {train_loss[epoch]:>7.6f}', end=', ')\n",
    "    print(f'Val Acc: {val_acc[epoch]:.4f}, Val Loss: {val_loss[epoch]:>7.6f}', end=' -- ')\n",
    "    print(f'Training Time: {_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7989742e-ee72-4028-a257-4395562e3ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab5e56-918f-4f1b-9ee2-8a90b70f6894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56221847-0a6d-4b8d-bef3-69c5fe0587da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
